{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import random\n",
    "from ipywidgets import interact, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython import display\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import sys\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bjornjuel/projects/Renzo_AA/actual_agency_old/src/ActualAgency\n",
      "\n",
      "Welcome to PyPhi!\n",
      "\n",
      "If you use PyPhi in your research, please cite the paper:\n",
      "\n",
      "  Mayner WGP, Marshall W, Albantakis L, Findlay G, Marchman R, Tononi G.\n",
      "  (2018). PyPhi: A toolbox for integrated information theory.\n",
      "  PLOS Computational Biology 14(7): e1006343.\n",
      "  https://doi.org/10.1371/journal.pcbi.1006343\n",
      "\n",
      "Documentation is available online (or with the built-in `help()` function):\n",
      "  https://pyphi.readthedocs.io\n",
      "\n",
      "To report issues, please use the issue tracker on the GitHub repository:\n",
      "  https://github.com/wmayner/pyphi\n",
      "\n",
      "For general discussion, you are welcome to join the pyphi-users group:\n",
      "  https://groups.google.com/forum/#!forum/pyphi-users\n",
      "\n",
      "To suppress this message, either:\n",
      "  - Set `WELCOME_OFF: true` in your `pyphi_config.yml` file, or\n",
      "  - Set the environment variable PYPHI_WELCOME_OFF to any value in your shell:\n",
      "        export PYPHI_WELCOME_OFF='yes'\n",
      "\n",
      "/Users/bjornjuel/projects/Renzo_AA/actual_agency_old/src/pyphi\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "\n",
    "#path = os.path.join(basepath,'actual_agency')\n",
    "path = os.path.join(basepath,'actual_agency_old/src/ActualAgency')\n",
    "print(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "from pyanimats import *\n",
    "from pyTPM import *\n",
    "import actual_agency as agency\n",
    "\n",
    "path = os.path.join(basepath,'actual_agency_old/src/pyphi')\n",
    "print(path)\n",
    "sys.path.append(path)\n",
    "\n",
    "import pyphi\n",
    "from pyphi import actual, config, Direction\n",
    "pyphi.config.VALIDATE_SUBSYSTEM_STATES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport pyTPM, pyanimats, actual_agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets inspect the fitness of the animats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, tell the computer where to look for files\n",
    "#basepath = '/Users/bjornjuel/projects/mabe/new_branch/MABE/Experiments/'\n",
    "#basepath = '/Users/bjornjuel/projects/mabe_development/mabe/Experiments/'\n",
    "basepath = '/Users/bjornjuel/projects/Renzo_AA/mabe_2sensor/Experiments/'\n",
    "path = os.path.join(basepath,'replacetest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Line-of-descent (LOD) data from MABE output\n",
    "with open(os.path.join(path,'LOD_data.pkl'),'rb') as f:\n",
    "    LOD_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fitness to the LOD data structure\n",
    "generations = 10000\n",
    "n_agents = int(generations/500.+1)\n",
    "n_runs = 25\n",
    "n_trials = 64\n",
    "\n",
    "run = 0\n",
    "agent = 2\n",
    "trial = 5\n",
    "transition = 10\n",
    "\n",
    "for n in range(n_runs):\n",
    "    LOD_data[n]['fitness'] = (LOD_data[n]['correct_AVE']\n",
    "                               /(LOD_data[n]['correct_AVE']+LOD_data[n]['incorrect_AVE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.500000\n",
       "1     0.515625\n",
       "2     0.718750\n",
       "3     0.718750\n",
       "4     0.718750\n",
       "5     0.781250\n",
       "6     0.781250\n",
       "7     0.781250\n",
       "8     0.781250\n",
       "9     0.781250\n",
       "10    0.781250\n",
       "11    0.781250\n",
       "12    0.781250\n",
       "13    0.781250\n",
       "14    0.781250\n",
       "15    0.781250\n",
       "16    0.781250\n",
       "17    0.781250\n",
       "18    0.781250\n",
       "19    0.781250\n",
       "20    0.781250\n",
       "Name: fitness, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the fitness of a specific LOD (run)\n",
    "heading = 'fitness'\n",
    "LOD_data[run][heading][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update</th>\n",
       "      <th>timeToCoalescence</th>\n",
       "      <th>ID</th>\n",
       "      <th>alive</th>\n",
       "      <th>correct_AVE</th>\n",
       "      <th>correct_LIST</th>\n",
       "      <th>genomeLength</th>\n",
       "      <th>incorrect_AVE</th>\n",
       "      <th>incorrect_LIST</th>\n",
       "      <th>markovBrainDeterministicGates</th>\n",
       "      <th>markovBrainGates</th>\n",
       "      <th>markovBrain_nextNodesConnections_AVE</th>\n",
       "      <th>markovBrain_nextNodesConnections_LIST</th>\n",
       "      <th>markovBrain_nodesConnections_AVE</th>\n",
       "      <th>markovBrain_nodesConnections_LIST</th>\n",
       "      <th>optimizeValue</th>\n",
       "      <th>score_AVE</th>\n",
       "      <th>score_LIST</th>\n",
       "      <th>timeOfBirth</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1,0,1,0,1,0,0,2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1,0,1,0,0,0,3,0</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>50023</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5753</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0,1,2,0,3,0,2,4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3,0,0,0,0,1,4,0</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>0.907029</td>\n",
       "      <td>499</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100019</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3858</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.375</td>\n",
       "      <td>3,3,1,1,0,0,3,0</td>\n",
       "      <td>1.500</td>\n",
       "      <td>5,1,0,3,0,0,3,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>150078</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>4034</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0,0,1,1,0,2,2,2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3,1,0,0,1,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>1499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>200020</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>5313</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2,1,1,1,0,1,1,0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3,1,0,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>250016</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>8507</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2,0,1,1,1,1,1,0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3,1,1,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>2499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>300030</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>7954</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1,0,1,1,2,1,1,0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3,1,0,0,0,0,2,1</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>2999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3500</td>\n",
       "      <td>0</td>\n",
       "      <td>350048</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6368</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0,2,1,1,1,0,1,0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3,1,0,0,0,1,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>3499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>400015</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>4078</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1,4,1,1,1,0,1,3</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5,1,1,0,0,0,3,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>3999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>450066</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>7300</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0,2,1,1,1,1,1,0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3,1,1,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>4499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>500039</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>7181</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>2,0,1,1,2,0,1,0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3,1,0,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>4999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5500</td>\n",
       "      <td>0</td>\n",
       "      <td>550090</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3877</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0,2,1,1,3,1,1,1</td>\n",
       "      <td>1.125</td>\n",
       "      <td>4,1,0,0,0,0,3,1</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>5499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "      <td>600060</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2179</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1,3,1,2,2,0,1,0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>3,1,0,2,0,0,3,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>5999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6500</td>\n",
       "      <td>0</td>\n",
       "      <td>650051</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6769</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2,2,1,2,1,1,1,0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>3,1,0,0,0,0,5,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>6499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "      <td>700072</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>10706</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.875</td>\n",
       "      <td>1,4,1,1,3,4,1,0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2,1,0,0,0,0,5,1</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>6999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>750083</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>6071</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0,3,1,2,0,1,1,0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3,1,0,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>7499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>800047</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>7096</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1,0,1,2,0,1,1,2</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2,1,1,0,0,0,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>7999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8500</td>\n",
       "      <td>0</td>\n",
       "      <td>850052</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0,2,1,1,0,0,1,0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2,1,0,0,0,1,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>8499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "      <td>900044</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1917</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0,2,1,4,2,0,1,0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3,1,1,0,0,0,3,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>8999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9500</td>\n",
       "      <td>0</td>\n",
       "      <td>950084</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3851</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1,1,1,1,1,0,1,1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2,1,0,0,0,1,2,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>9499</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10000</td>\n",
       "      <td>215</td>\n",
       "      <td>1000005</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2762</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2,2,2,1,0,0,2,0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3,2,0,0,0,0,3,0</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>11.467400</td>\n",
       "      <td>9999</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    update  timeToCoalescence       ID  alive  correct_AVE  correct_LIST  \\\n",
       "0        0                  0        6      1         31.0            31   \n",
       "1      500                  0    50023      1         31.0            31   \n",
       "2     1000                  0   100019      1         57.0            57   \n",
       "3     1500                  0   150078      1         57.0            57   \n",
       "4     2000                  0   200020      1         57.0            57   \n",
       "5     2500                  0   250016      1         57.0            57   \n",
       "6     3000                  0   300030      1         57.0            57   \n",
       "7     3500                  0   350048      1         57.0            57   \n",
       "8     4000                  0   400015      1         57.0            57   \n",
       "9     4500                  0   450066      1         57.0            57   \n",
       "10    5000                  0   500039      1         57.0            57   \n",
       "11    5500                  0   550090      1         57.0            57   \n",
       "12    6000                  0   600060      1         57.0            57   \n",
       "13    6500                  0   650051      1         57.0            57   \n",
       "14    7000                  0   700072      1         57.0            57   \n",
       "15    7500                  0   750083      1         57.0            57   \n",
       "16    8000                  0   800047      1         57.0            57   \n",
       "17    8500                  0   850052      1         57.0            57   \n",
       "18    9000                  0   900044      1         57.0            57   \n",
       "19    9500                  0   950084      1         57.0            57   \n",
       "20   10000                215  1000005      1         57.0            57   \n",
       "\n",
       "    genomeLength  incorrect_AVE  incorrect_LIST  \\\n",
       "0           5000           33.0              33   \n",
       "1           5753           33.0              33   \n",
       "2           3858            7.0               7   \n",
       "3           4034            7.0               7   \n",
       "4           5313            7.0               7   \n",
       "5           8507            7.0               7   \n",
       "6           7954            7.0               7   \n",
       "7           6368            7.0               7   \n",
       "8           4078            7.0               7   \n",
       "9           7300            7.0               7   \n",
       "10          7181            7.0               7   \n",
       "11          3877            7.0               7   \n",
       "12          2179            7.0               7   \n",
       "13          6769            7.0               7   \n",
       "14         10706            7.0               7   \n",
       "15          6071            7.0               7   \n",
       "16          7096            7.0               7   \n",
       "17          2631            7.0               7   \n",
       "18          1917            7.0               7   \n",
       "19          3851            7.0               7   \n",
       "20          2762            7.0               7   \n",
       "\n",
       "    markovBrainDeterministicGates  markovBrainGates  \\\n",
       "0                               2                 2   \n",
       "1                               3                 3   \n",
       "2                               3                 3   \n",
       "3                               2                 2   \n",
       "4                               2                 2   \n",
       "5                               2                 2   \n",
       "6                               2                 2   \n",
       "7                               2                 2   \n",
       "8                               3                 3   \n",
       "9                               2                 2   \n",
       "10                              2                 2   \n",
       "11                              3                 3   \n",
       "12                              3                 3   \n",
       "13                              3                 3   \n",
       "14                              4                 4   \n",
       "15                              2                 2   \n",
       "16                              2                 2   \n",
       "17                              2                 2   \n",
       "18                              3                 3   \n",
       "19                              2                 2   \n",
       "20                              3                 3   \n",
       "\n",
       "    markovBrain_nextNodesConnections_AVE  \\\n",
       "0                                  0.625   \n",
       "1                                  1.500   \n",
       "2                                  1.375   \n",
       "3                                  1.000   \n",
       "4                                  0.875   \n",
       "5                                  0.875   \n",
       "6                                  0.875   \n",
       "7                                  0.750   \n",
       "8                                  1.500   \n",
       "9                                  0.875   \n",
       "10                                 0.875   \n",
       "11                                 1.250   \n",
       "12                                 1.250   \n",
       "13                                 1.250   \n",
       "14                                 1.875   \n",
       "15                                 1.000   \n",
       "16                                 1.000   \n",
       "17                                 0.625   \n",
       "18                                 1.250   \n",
       "19                                 0.875   \n",
       "20                                 1.125   \n",
       "\n",
       "   markovBrain_nextNodesConnections_LIST  markovBrain_nodesConnections_AVE  \\\n",
       "0                        1,0,1,0,1,0,0,2                             0.625   \n",
       "1                        0,1,2,0,3,0,2,4                             1.000   \n",
       "2                        3,3,1,1,0,0,3,0                             1.500   \n",
       "3                        0,0,1,1,0,2,2,2                             0.875   \n",
       "4                        2,1,1,1,0,1,1,0                             0.750   \n",
       "5                        2,0,1,1,1,1,1,0                             0.875   \n",
       "6                        1,0,1,1,2,1,1,0                             0.875   \n",
       "7                        0,2,1,1,1,0,1,0                             0.875   \n",
       "8                        1,4,1,1,1,0,1,3                             1.250   \n",
       "9                        0,2,1,1,1,1,1,0                             0.875   \n",
       "10                       2,0,1,1,2,0,1,0                             0.750   \n",
       "11                       0,2,1,1,3,1,1,1                             1.125   \n",
       "12                       1,3,1,2,2,0,1,0                             1.125   \n",
       "13                       2,2,1,2,1,1,1,0                             1.125   \n",
       "14                       1,4,1,1,3,4,1,0                             1.125   \n",
       "15                       0,3,1,2,0,1,1,0                             0.750   \n",
       "16                       1,0,1,2,0,1,1,2                             0.750   \n",
       "17                       0,2,1,1,0,0,1,0                             0.750   \n",
       "18                       0,2,1,4,2,0,1,0                             1.000   \n",
       "19                       1,1,1,1,1,0,1,1                             0.750   \n",
       "20                       2,2,2,1,0,0,2,0                             1.000   \n",
       "\n",
       "   markovBrain_nodesConnections_LIST  optimizeValue  score_AVE  score_LIST  \\\n",
       "0                    1,0,1,0,0,0,3,0       0.907029   0.907029    0.907029   \n",
       "1                    3,0,0,0,0,1,4,0       0.907029   0.907029    0.907029   \n",
       "2                    5,1,0,3,0,0,3,0      11.467400  11.467400   11.467400   \n",
       "3                    3,1,0,0,1,0,2,0      11.467400  11.467400   11.467400   \n",
       "4                    3,1,0,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "5                    3,1,1,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "6                    3,1,0,0,0,0,2,1      11.467400  11.467400   11.467400   \n",
       "7                    3,1,0,0,0,1,2,0      11.467400  11.467400   11.467400   \n",
       "8                    5,1,1,0,0,0,3,0      11.467400  11.467400   11.467400   \n",
       "9                    3,1,1,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "10                   3,1,0,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "11                   4,1,0,0,0,0,3,1      11.467400  11.467400   11.467400   \n",
       "12                   3,1,0,2,0,0,3,0      11.467400  11.467400   11.467400   \n",
       "13                   3,1,0,0,0,0,5,0      11.467400  11.467400   11.467400   \n",
       "14                   2,1,0,0,0,0,5,1      11.467400  11.467400   11.467400   \n",
       "15                   3,1,0,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "16                   2,1,1,0,0,0,2,0      11.467400  11.467400   11.467400   \n",
       "17                   2,1,0,0,0,1,2,0      11.467400  11.467400   11.467400   \n",
       "18                   3,1,1,0,0,0,3,0      11.467400  11.467400   11.467400   \n",
       "19                   2,1,0,0,0,1,2,0      11.467400  11.467400   11.467400   \n",
       "20                   3,2,0,0,0,0,3,0      11.467400  11.467400   11.467400   \n",
       "\n",
       "    timeOfBirth   fitness  \n",
       "0            -1  0.484375  \n",
       "1           499  0.484375  \n",
       "2           999  0.890625  \n",
       "3          1499  0.890625  \n",
       "4          1999  0.890625  \n",
       "5          2499  0.890625  \n",
       "6          2999  0.890625  \n",
       "7          3499  0.890625  \n",
       "8          3999  0.890625  \n",
       "9          4499  0.890625  \n",
       "10         4999  0.890625  \n",
       "11         5499  0.890625  \n",
       "12         5999  0.890625  \n",
       "13         6499  0.890625  \n",
       "14         6999  0.890625  \n",
       "15         7499  0.890625  \n",
       "16         7999  0.890625  \n",
       "17         8499  0.890625  \n",
       "18         8999  0.890625  \n",
       "19         9499  0.890625  \n",
       "20         9999  0.890625  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOD_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOD_data[0][heading][n_agents-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.515625, 0.71875, 0.71875, 0.71875, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125]\n",
      "[0.484375, 0.484375, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625]\n",
      "[0.5, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125, 0.703125]\n",
      "[0.484375, 0.859375, 0.859375, 0.859375, 0.953125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.484375, 0.765625, 0.796875, 0.875, 0.921875, 0.921875, 0.921875, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375]\n",
      "[0.484375, 0.71875, 0.765625, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.796875, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125, 0.8125]\n",
      "[0.484375, 0.9375, 0.9375, 0.9375, 0.96875, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.96875]\n",
      "[0.484375, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875, 0.96875]\n",
      "[0.484375, 0.546875, 0.703125, 0.703125, 0.8125, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625]\n",
      "[0.484375, 0.96875, 0.984375, 0.984375, 0.984375, 0.96875, 0.96875, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375]\n",
      "[0.484375, 0.765625, 0.765625, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125]\n",
      "[0.484375, 0.78125, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.78125]\n",
      "[0.484375, 0.484375, 0.484375, 0.703125, 0.765625, 0.765625, 0.8125, 0.921875, 0.9375, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125, 0.953125]\n",
      "[0.5, 0.5, 0.765625, 0.765625, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.828125, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.984375]\n",
      "[0.484375, 0.828125, 0.828125, 0.828125, 0.84375, 0.84375, 0.84375, 0.84375, 0.84375, 0.84375, 0.84375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375]\n",
      "[0.484375, 0.84375, 0.84375, 0.84375, 0.84375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375]\n",
      "[0.484375, 0.765625, 0.765625, 0.765625, 0.765625, 0.78125, 0.78125, 0.9375, 0.953125, 0.953125, 0.953125, 0.984375, 0.984375, 0.984375, 1.0, 0.984375, 0.96875, 0.984375, 0.984375, 0.984375, 0.984375]\n",
      "[0.484375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375, 0.859375]\n",
      "[0.484375, 0.78125, 0.78125, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375, 0.984375]\n",
      "[0.484375, 0.765625, 0.765625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.5625, 0.640625, 0.640625, 0.84375, 0.890625, 0.890625, 0.890625, 0.890625, 0.890625, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875, 0.921875]\n",
      "[0.46875, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.78125, 0.8125, 0.921875, 0.90625, 0.984375, 0.984375, 0.984375]\n",
      "[0.484375, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.90625, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375]\n",
      "[0.5, 0.84375, 0.875, 0.875, 0.875, 0.875, 0.875, 0.96875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.484375, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.765625, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and write the values to a new list\n",
    "fitness_data = [[LOD_data[r][heading][i] for i in range(n_agents)] for r in range(n_runs)]\n",
    "[print(x) for x in fitness_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's look at the genome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the genome from our output\n",
    "with open(os.path.join(path,'genome.pkl'),'rb') as f:\n",
    "    all_genomes = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENOME_root::_genomeLength</th>\n",
       "      <th>GENOME_root::_sites</th>\n",
       "      <th>ID</th>\n",
       "      <th>update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>204,76,49,36,50,212,75,165,141,104,51,59,26,10...</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8159</td>\n",
       "      <td>93,249,150,20,168,35,46,86,74,29,218,249,184,4...</td>\n",
       "      <td>50063</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8952</td>\n",
       "      <td>66,63,220,115,153,126,4,86,175,222,27,242,229,...</td>\n",
       "      <td>100046</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12860</td>\n",
       "      <td>87,36,147,122,50,205,128,183,39,106,208,57,218...</td>\n",
       "      <td>150050</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15582</td>\n",
       "      <td>222,248,0,224,148,28,44,221,5,193,5,33,109,36,...</td>\n",
       "      <td>200057</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15354</td>\n",
       "      <td>26,63,84,70,39,34,241,206,28,222,40,251,1,204,...</td>\n",
       "      <td>250075</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14655</td>\n",
       "      <td>118,251,191,28,89,254,190,197,11,101,126,157,8...</td>\n",
       "      <td>300071</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13690</td>\n",
       "      <td>10,136,8,148,208,252,213,57,128,132,28,112,54,...</td>\n",
       "      <td>350085</td>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10153</td>\n",
       "      <td>102,184,115,49,97,240,196,62,128,135,255,87,20...</td>\n",
       "      <td>400025</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8478</td>\n",
       "      <td>102,184,70,194,221,46,200,144,6,58,226,202,62,...</td>\n",
       "      <td>450023</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16099</td>\n",
       "      <td>214,36,100,36,221,240,242,92,70,142,211,249,19...</td>\n",
       "      <td>500058</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20205</td>\n",
       "      <td>209,189,132,154,11,155,242,114,123,142,181,249...</td>\n",
       "      <td>550049</td>\n",
       "      <td>5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16680</td>\n",
       "      <td>221,49,227,144,93,36,73,166,217,5,8,73,9,81,11...</td>\n",
       "      <td>600075</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16953</td>\n",
       "      <td>147,36,7,245,17,36,73,166,94,211,97,88,9,23,16...</td>\n",
       "      <td>650004</td>\n",
       "      <td>6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20391</td>\n",
       "      <td>104,144,133,245,108,181,154,28,126,73,99,167,8...</td>\n",
       "      <td>700007</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20293</td>\n",
       "      <td>41,90,44,39,44,72,22,237,217,154,99,148,218,11...</td>\n",
       "      <td>750045</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18516</td>\n",
       "      <td>67,91,7,162,133,92,182,237,217,114,121,95,78,1...</td>\n",
       "      <td>800025</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13720</td>\n",
       "      <td>122,91,124,162,232,209,87,4,29,232,103,95,111,...</td>\n",
       "      <td>850060</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14482</td>\n",
       "      <td>122,202,133,203,221,148,49,166,102,18,35,12,24...</td>\n",
       "      <td>900079</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12755</td>\n",
       "      <td>69,146,221,187,77,38,67,22,188,91,60,32,47,231...</td>\n",
       "      <td>950053</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14036</td>\n",
       "      <td>51,13,174,158,89,38,55,233,31,95,217,62,47,189...</td>\n",
       "      <td>1000032</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GENOME_root::_genomeLength  \\\n",
       "0                         5000   \n",
       "1                         8159   \n",
       "2                         8952   \n",
       "3                        12860   \n",
       "4                        15582   \n",
       "5                        15354   \n",
       "6                        14655   \n",
       "7                        13690   \n",
       "8                        10153   \n",
       "9                         8478   \n",
       "10                       16099   \n",
       "11                       20205   \n",
       "12                       16680   \n",
       "13                       16953   \n",
       "14                       20391   \n",
       "15                       20293   \n",
       "16                       18516   \n",
       "17                       13720   \n",
       "18                       14482   \n",
       "19                       12755   \n",
       "20                       14036   \n",
       "\n",
       "                                  GENOME_root::_sites       ID  update  \n",
       "0   204,76,49,36,50,212,75,165,141,104,51,59,26,10...       56       0  \n",
       "1   93,249,150,20,168,35,46,86,74,29,218,249,184,4...    50063     500  \n",
       "2   66,63,220,115,153,126,4,86,175,222,27,242,229,...   100046    1000  \n",
       "3   87,36,147,122,50,205,128,183,39,106,208,57,218...   150050    1500  \n",
       "4   222,248,0,224,148,28,44,221,5,193,5,33,109,36,...   200057    2000  \n",
       "5   26,63,84,70,39,34,241,206,28,222,40,251,1,204,...   250075    2500  \n",
       "6   118,251,191,28,89,254,190,197,11,101,126,157,8...   300071    3000  \n",
       "7   10,136,8,148,208,252,213,57,128,132,28,112,54,...   350085    3500  \n",
       "8   102,184,115,49,97,240,196,62,128,135,255,87,20...   400025    4000  \n",
       "9   102,184,70,194,221,46,200,144,6,58,226,202,62,...   450023    4500  \n",
       "10  214,36,100,36,221,240,242,92,70,142,211,249,19...   500058    5000  \n",
       "11  209,189,132,154,11,155,242,114,123,142,181,249...   550049    5500  \n",
       "12  221,49,227,144,93,36,73,166,217,5,8,73,9,81,11...   600075    6000  \n",
       "13  147,36,7,245,17,36,73,166,94,211,97,88,9,23,16...   650004    6500  \n",
       "14  104,144,133,245,108,181,154,28,126,73,99,167,8...   700007    7000  \n",
       "15  41,90,44,39,44,72,22,237,217,154,99,148,218,11...   750045    7500  \n",
       "16  67,91,7,162,133,92,182,237,217,114,121,95,78,1...   800025    8000  \n",
       "17  122,91,124,162,232,209,87,4,29,232,103,95,111,...   850060    8500  \n",
       "18  122,202,133,203,221,148,49,166,102,18,35,12,24...   900079    9000  \n",
       "19  69,146,221,187,77,38,67,22,188,91,60,32,47,231...   950053    9500  \n",
       "20  51,13,174,158,89,38,55,233,31,95,217,62,47,189...  1000032   10000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genomes[run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can pick the genome of one agent and parse it (make it readable for our scripts) \n",
    "genome = agency.get_genome(all_genomes, run, agent)\n",
    "\n",
    "# from the genome we can reconstruct the TPM (transition probability matrix) and CM (connectivity matrix)\n",
    "TPM, TPM_gates, cm = genome2TPM(genome, n_nodes=8, n_sensors=2, n_motors=2, gate_type='deterministic',states_convention='loli',remove_sensor_motor_effects=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  1.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  0.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  0. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  0.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  1.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n",
      "[0.5 0.5 0.  1.  0.  1.  0.  1. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we can inspect the TPM\n",
    "[print(x) for x in TPM] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'deterministic',\n",
       "  'ins': array([4, 7, 6, 0]),\n",
       "  'outs': array([5, 3]),\n",
       "  'logic': [[0.0, 0.0],\n",
       "   [1.0, 0.0],\n",
       "   [0.0, 1.0],\n",
       "   [0.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 0.0],\n",
       "   [1.0, 1.0],\n",
       "   [1.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 1.0],\n",
       "   [1.0, 1.0]]},\n",
       " {'type': 'deterministic',\n",
       "  'ins': array([6]),\n",
       "  'outs': array([4]),\n",
       "  'logic': [[0.0], [0.0]]},\n",
       " {'type': 'deterministic',\n",
       "  'ins': array([6, 7, 1, 3]),\n",
       "  'outs': array([7, 4]),\n",
       "  'logic': [[0.0, 0.0],\n",
       "   [0.0, 0.0],\n",
       "   [1.0, 0.0],\n",
       "   [1.0, 1.0],\n",
       "   [1.0, 1.0],\n",
       "   [1.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [1.0, 0.0],\n",
       "   [1.0, 1.0],\n",
       "   [1.0, 1.0],\n",
       "   [1.0, 1.0],\n",
       "   [0.0, 0.0],\n",
       "   [0.0, 1.0],\n",
       "   [0.0, 1.0],\n",
       "   [1.0, 0.0],\n",
       "   [0.0, 0.0]]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the gate specific TPMS\n",
    "TPM_gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# and also the connectivity matrix (CM)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last part of the output is the activity pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the data from our MABE output\n",
    "with open(os.path.join(path,'activity.pkl'),'rb') as f:\n",
    "    activity = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n",
      "Creating activity matrix from MABE output...\n"
     ]
    }
   ],
   "source": [
    "# reformat the activity to a single list for each trial\n",
    "brain_activity = []\n",
    "for r in range(n_runs):\n",
    "    brain_activity.append(agency.getBrainActivity(activity[r], n_agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# inspect activity for a given run, agent, and trial\n",
    "\n",
    "print(brain_activity[run][agent][trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1252b0690>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting activity of the wait'th trial of each trial type\n",
    "wait = 4\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(brain_activity[run][agent][0+wait])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(brain_activity[run][agent][16+wait])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(brain_activity[run][agent][32+wait])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(brain_activity[run][agent][48+wait])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next step is doing some actual causation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition from [0. 0. 0. 0. 1. 0. 0. 1.] to [0. 0. 0. 1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# let's analyse the actual causes of the motor occurences for the animat in one trial\n",
    "\n",
    "# First we can inspect the occurrences\n",
    "X,Y = agency.get_occurrences(np.array(brain_activity[run][agent]),numSensors=2,numHidden=4,numMotors=2)\n",
    "print('transition from {} to {}'.format(X[trial][transition],Y[trial][transition]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to actually do the AC analysis we must first define a network for pyphi\n",
    "network = pyphi.network.Network(np.array(TPM), cm=np.array(cm), \n",
    "            node_labels=('S1','S2','M1','M2','H1','H2','H3','H4'), purview_cache=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can run a script for calculating the direct causes of all motor occurrences\n",
    "purview, alpha, motorstate, transitions, account = agency.AnalyzeTransitions(\n",
    "            network, brain_activity[run][agent][trial], \n",
    "            cause_indices=[0,1,4,5,6,7], effect_indices=[2,3],\n",
    "            sensor_indices=[0,1], motor_indices=[2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account[0].causal_links[0].purview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkTPM(tpm,activity):\n",
    "    TPMmulti = pyphi.convert.to_multidimensional(tpm)\n",
    "    \n",
    "    diff = 0\n",
    "    for t in range(0,activity.shape[0]-1):\n",
    "        predicted = TPMmulti[tuple(activity[t].astype(int).tolist())]\n",
    "        diff += np.sum(np.array([(predicted[i]-activity[t+1][i])**2 for i in range(2,len(activity[t].astype(int).tolist()))]))\n",
    "        #print(predicted)\n",
    "        #print(activity[t+1])\n",
    "        #print(' ')\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-50cb29d632ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mgenome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_genome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_genomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mTPM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPM_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenome2TPM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_motors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deterministic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates_convention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loli'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mremove_sensor_motor_effects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_activity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Renzo_AA/actual_agency_old/src/ActualAgency/pyTPM.py\u001b[0m in \u001b[0;36mgenome2TPM\u001b[0;34m(genome, n_nodes, n_sensors, n_motors, gate_type, states_convention, remove_sensor_motor_effects)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfull_TPM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_gate_TPM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_TPM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_convention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mstart_codon\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# (Deterministic)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mfull_TPM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_gate_TPM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_TPM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_convention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mTPM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfull_TPM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Renzo_AA/actual_agency_old/src/ActualAgency/pyTPM.py\u001b[0m in \u001b[0;36mexpand_gate_TPM\u001b[0;34m(gate_TPM, inputs, outputs, n_nodes, states_convention)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_gate_TPM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate through rows (inputs states)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_TPM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfull_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0mexpanded_gate_TPM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgate_TPM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m     \"\"\"\n\u001b[0;32m-> 2351\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = []\n",
    "for run in range(n_runs):\n",
    "    for agent in range(n_agents):\n",
    "        for trial in range(n_trials):\n",
    "            genome = agency.get_genome(all_genomes, run, agent)\n",
    "            TPM, TPM_gates, cm = genome2TPM(genome, n_nodes=8, n_sensors=2, n_motors=2, gate_type='deterministic',states_convention='loli',remove_sensor_motor_effects=True)\n",
    "\n",
    "            act = brain_activity[run][agent][trial]\n",
    "            d.append(checkTPM(TPM,act))\n",
    "print(np.sum(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can pick the genome of one agent and parse it (make it readable for our scripts) \n",
    "genome = agency.get_genome(all_genomes, run, agent)\n",
    "\n",
    "# from the genome we can reconstruct the TPM (transition probability matrix) and CM (connectivity matrix)\n",
    "TPM, TPM_gates, cm = genome2TPM(genome, n_nodes=8, n_sensors=2, n_motors=2, gate_type='deterministic',states_convention='loli',remove_sensor_motor_effects=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
